# INGESTA OPTIMIZADA - Versi√≥n Mejorada (Opcional, no necesaria con pre-carga en API)
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
import os
import time
import shutil

# --- Configuraci√≥n Optimizada ---
RUTA_DOCUMENTO = "Syllabus.pdf" 
NOMBRE_COLECCION = "asistente_educativo_utem" 
PERSIST_DIRECTORY = "./chroma_db"

if not os.path.exists(RUTA_DOCUMENTO):
    print(f"‚ùå ERROR: No se encontr√≥ '{RUTA_DOCUMENTO}'")
    print("Col√≥calo en la misma carpeta que este script.")
    exit()

print("=" * 70)
print("üöÄ INGESTA OPTIMIZADA DE DATOS")
print("=" * 70)
inicio_total = time.time()

# 1. Carga de Documentos
print("\n[1/4] üìÑ Cargando PDF...")
inicio = time.time()
try:
    loader = PyPDFLoader(RUTA_DOCUMENTO)
    documentos = loader.load()
    tiempo = time.time() - inicio
    print(f"   ‚úÖ {len(documentos)} p√°ginas cargadas en {tiempo:.2f}s")
except Exception as e:
    print(f"   ‚ùå Error: {e}")
    exit()

# 2. Fragmentaci√≥n OPTIMIZADA
print("\n[2/4] ‚úÇÔ∏è  Fragmentando texto...")
inicio = time.time()

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=150,
    separators=["\n\n", "\n", ". ", " ", ""],
    length_function=len,
)

fragmentos = text_splitter.split_documents(documentos)
tiempo = time.time() - inicio

print(f"   ‚úÖ {len(fragmentos)} fragmentos creados en {tiempo:.2f}s")
print(f"   üìä Tama√±o promedio: {sum(len(f.page_content) for f in fragmentos) // len(fragmentos)} caracteres")

# 3. Embeddings Optimizados
print("\n[3/4] üß† Inicializando modelo de embeddings...")
inicio = time.time()

embeddings_model = HuggingFaceEmbeddings(
    model_name="all-MiniLM-L6-v2",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True, 'batch_size': 64}
)

tiempo = time.time() - inicio
print(f"   ‚úÖ Modelo cargado en {tiempo:.2f}s")

# 4. Almacenamiento en ChromaDB OPTIMIZADO
print("\n[4/4] üíæ Creando base de datos vectorial...")
inicio = time.time()

if os.path.exists(PERSIST_DIRECTORY):
    shutil.rmtree(PERSIST_DIRECTORY)
    print(f"   üóëÔ∏è  Base de datos anterior eliminada")

vector_store = Chroma.from_documents(
    documents=fragmentos, 
    embedding=embeddings_model, 
    collection_name=NOMBRE_COLECCION,
    persist_directory=PERSIST_DIRECTORY,
    collection_metadata={"hnsw:space": "cosine", "hnsw:construction_ef": 100, "hnsw:M": 16}
)

tiempo = time.time() - inicio
tiempo_total = time.time() - inicio_total

print(f"   ‚úÖ Base de datos creada en {time.time() - inicio:.2f}s")

cantidad = vector_store._collection.count()
print(f"\n{'=' * 70}")
print(f"‚úÖ INGESTA COMPLETADA EXITOSAMENTE")
print(f"{'=' * 70}")
print(f"‚è±Ô∏è  Tiempo total: {tiempo_total:.2f} segundos")
print(f"üìä Fragmentos almacenados: {cantidad}")
print(f"üíæ Ubicaci√≥n: {PERSIST_DIRECTORY}/")
print(f"üéØ Colecci√≥n: {NOMBRE_COLECCION}")
print(f"\nüöÄ Siguiente paso: uvicorn api_fastapi:app --reload (opcional, pre-carga en API)")
print(f"{'=' * 70}")